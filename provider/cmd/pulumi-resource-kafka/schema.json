{
    "name": "kafka",
    "description": "A Pulumi package for creating and managing Kafka.",
    "keywords": [
        "pulumi",
        "kafka"
    ],
    "homepage": "https://pulumi.io",
    "license": "Apache-2.0",
    "attribution": "This Pulumi package is based on the [`kafka` Terraform Provider](https://github.com/Mongey/terraform-provider-kafka).",
    "repository": "https://github.com/pulumi/pulumi-kafka",
    "meta": {
        "moduleFormat": "(.*)(?:/[^/]*)"
    },
    "language": {
        "csharp": {
            "packageReferences": {
                "Pulumi": "3.*"
            },
            "namespaces": {
                "kafka": "Kafka"
            },
            "compatibility": "tfbridge20",
            "respectSchemaVersion": true
        },
        "go": {
            "importBasePath": "github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka",
            "generateResourceContainerTypes": true,
            "generateExtraInputTypes": true,
            "respectSchemaVersion": true
        },
        "nodejs": {
            "packageDescription": "A Pulumi package for creating and managing Kafka.",
            "readme": "\u003e This provider is a derived work of the [Terraform Provider](https://github.com/Mongey/terraform-provider-kafka)\n\u003e distributed under [MIT](https://mit-license.org/). If you encounter a bug or missing feature,\n\u003e first check the [`pulumi-kafka` repo](https://github.com/pulumi/pulumi-kafka/issues); however, if that doesn't turn up anything,\n\u003e please consult the source [`terraform-provider-kafka` repo](https://github.com/Mongey/terraform-provider-kafka/issues).",
            "compatibility": "tfbridge20",
            "disableUnionOutputTypes": true,
            "respectSchemaVersion": true
        },
        "python": {
            "readme": "\u003e This provider is a derived work of the [Terraform Provider](https://github.com/Mongey/terraform-provider-kafka)\n\u003e distributed under [MIT](https://mit-license.org/). If you encounter a bug or missing feature,\n\u003e first check the [`pulumi-kafka` repo](https://github.com/pulumi/pulumi-kafka/issues); however, if that doesn't turn up anything,\n\u003e please consult the source [`terraform-provider-kafka` repo](https://github.com/Mongey/terraform-provider-kafka/issues).",
            "compatibility": "tfbridge20",
            "respectSchemaVersion": true,
            "pyproject": {
                "enabled": true
            }
        }
    },
    "config": {
        "variables": {
            "bootstrapServers": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "A list of kafka brokers\n"
            },
            "caCert": {
                "type": "string",
                "description": "CA certificate file to validate the server's certificate.\n"
            },
            "caCertFile": {
                "type": "string",
                "description": "Path to a CA certificate file to validate the server's certificate.\n",
                "deprecationMessage": "This parameter is now deprecated and will be removed in a later release, please use `ca_cert` instead."
            },
            "clientCert": {
                "type": "string",
                "description": "The client certificate.\n"
            },
            "clientCertFile": {
                "type": "string",
                "description": "Path to a file containing the client certificate.\n",
                "deprecationMessage": "This parameter is now deprecated and will be removed in a later release, please use `client_cert` instead."
            },
            "clientKey": {
                "type": "string",
                "description": "The private key that the certificate was issued for.\n"
            },
            "clientKeyFile": {
                "type": "string",
                "description": "Path to a file containing the private key that the certificate was issued for.\n",
                "deprecationMessage": "This parameter is now deprecated and will be removed in a later release, please use `client_key` instead."
            },
            "clientKeyPassphrase": {
                "type": "string",
                "description": "The passphrase for the private key that the certificate was issued for.\n"
            },
            "kafkaVersion": {
                "type": "string",
                "description": "The version of Kafka protocol to use in `$MAJOR.$MINOR.$PATCH` format. Some features may not be available on older\nversions. Default is 2.7.0.\n"
            },
            "saslAwsAccessKey": {
                "type": "string",
                "description": "The AWS access key.\n"
            },
            "saslAwsContainerAuthorizationTokenFile": {
                "type": "string",
                "description": "Path to a file containing the AWS pod identity authorization token\n"
            },
            "saslAwsContainerCredentialsFullUri": {
                "type": "string",
                "description": "URI to retrieve AWS credentials from\n"
            },
            "saslAwsCredsDebug": {
                "type": "boolean",
                "description": "Set this to true to turn AWS credentials debug.\n"
            },
            "saslAwsExternalId": {
                "type": "string",
                "description": "External ID of the AWS IAM role to assume\n"
            },
            "saslAwsProfile": {
                "type": "string",
                "description": "AWS profile name to use\n"
            },
            "saslAwsRegion": {
                "type": "string",
                "description": "AWS region where MSK is deployed.\n"
            },
            "saslAwsRoleArn": {
                "type": "string",
                "description": "Arn of an AWS IAM role to assume\n"
            },
            "saslAwsSecretKey": {
                "type": "string",
                "description": "The AWS secret key.\n"
            },
            "saslAwsSharedConfigFiles": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "List of paths to AWS shared config files.\n"
            },
            "saslAwsToken": {
                "type": "string",
                "description": "The AWS session token. Only required if you are using temporary security credentials.\n"
            },
            "saslMechanism": {
                "type": "string",
                "description": "SASL mechanism, can be plain, scram-sha512, scram-sha256, aws-iam\n",
                "default": "plain",
                "defaultInfo": {
                    "environment": [
                        "KAFKA_SASL_MECHANISM"
                    ]
                }
            },
            "saslOauthScopes": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "OAuth scopes to request when using the oauthbearer mechanism\n"
            },
            "saslPassword": {
                "type": "string",
                "description": "Password for SASL authentication.\n"
            },
            "saslTokenUrl": {
                "type": "string",
                "description": "The url to retrieve oauth2 tokens from, when using sasl mechanism oauthbearer\n"
            },
            "saslUsername": {
                "type": "string",
                "description": "Username for SASL authentication.\n"
            },
            "skipTlsVerify": {
                "type": "boolean",
                "description": "Set this to true only if the target Kafka server is an insecure development instance.\n",
                "default": false,
                "defaultInfo": {
                    "environment": [
                        "KAFKA_SKIP_VERIFY"
                    ]
                }
            },
            "timeout": {
                "type": "integer",
                "description": "Timeout in seconds\n"
            },
            "tlsEnabled": {
                "type": "boolean",
                "description": "Enable communication with the Kafka Cluster over TLS.\n",
                "default": true,
                "defaultInfo": {
                    "environment": [
                        "KAFKA_ENABLE_TLS"
                    ]
                }
            }
        },
        "defaults": [
            "bootstrapServers"
        ]
    },
    "types": {
        "kafka:index/getTopicsList:getTopicsList": {
            "properties": {
                "config": {
                    "type": "object",
                    "additionalProperties": {
                        "type": "string"
                    },
                    "description": "A map of string k/v attributes.\n"
                },
                "partitions": {
                    "type": "integer",
                    "description": "Number of partitions.\n"
                },
                "replicationFactor": {
                    "type": "integer",
                    "description": "Number of replicas.\n"
                },
                "topicName": {
                    "type": "string",
                    "description": "The name of the topic.\n"
                }
            },
            "type": "object",
            "required": [
                "config",
                "partitions",
                "replicationFactor",
                "topicName"
            ],
            "language": {
                "nodejs": {
                    "requiredInputs": []
                }
            }
        }
    },
    "provider": {
        "description": "The provider type for the kafka package. By default, resources use package-wide configuration\nsettings, however an explicit `Provider` instance may be created and passed during resource\nconstruction to achieve fine-grained programmatic control over provider settings. See the\n[documentation](https://www.pulumi.com/docs/reference/programming-model/#providers) for more information.\n",
        "properties": {
            "bootstrapServers": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "A list of kafka brokers\n"
            },
            "caCert": {
                "type": "string",
                "description": "CA certificate file to validate the server's certificate.\n"
            },
            "caCertFile": {
                "type": "string",
                "description": "Path to a CA certificate file to validate the server's certificate.\n",
                "deprecationMessage": "This parameter is now deprecated and will be removed in a later release, please use `ca_cert` instead."
            },
            "clientCert": {
                "type": "string",
                "description": "The client certificate.\n"
            },
            "clientCertFile": {
                "type": "string",
                "description": "Path to a file containing the client certificate.\n",
                "deprecationMessage": "This parameter is now deprecated and will be removed in a later release, please use `client_cert` instead."
            },
            "clientKey": {
                "type": "string",
                "description": "The private key that the certificate was issued for.\n"
            },
            "clientKeyFile": {
                "type": "string",
                "description": "Path to a file containing the private key that the certificate was issued for.\n",
                "deprecationMessage": "This parameter is now deprecated and will be removed in a later release, please use `client_key` instead."
            },
            "clientKeyPassphrase": {
                "type": "string",
                "description": "The passphrase for the private key that the certificate was issued for.\n"
            },
            "kafkaVersion": {
                "type": "string",
                "description": "The version of Kafka protocol to use in `$MAJOR.$MINOR.$PATCH` format. Some features may not be available on older\nversions. Default is 2.7.0.\n"
            },
            "saslAwsAccessKey": {
                "type": "string",
                "description": "The AWS access key.\n"
            },
            "saslAwsContainerAuthorizationTokenFile": {
                "type": "string",
                "description": "Path to a file containing the AWS pod identity authorization token\n"
            },
            "saslAwsContainerCredentialsFullUri": {
                "type": "string",
                "description": "URI to retrieve AWS credentials from\n"
            },
            "saslAwsCredsDebug": {
                "type": "boolean",
                "description": "Set this to true to turn AWS credentials debug.\n"
            },
            "saslAwsExternalId": {
                "type": "string",
                "description": "External ID of the AWS IAM role to assume\n"
            },
            "saslAwsProfile": {
                "type": "string",
                "description": "AWS profile name to use\n"
            },
            "saslAwsRegion": {
                "type": "string",
                "description": "AWS region where MSK is deployed.\n"
            },
            "saslAwsRoleArn": {
                "type": "string",
                "description": "Arn of an AWS IAM role to assume\n"
            },
            "saslAwsSecretKey": {
                "type": "string",
                "description": "The AWS secret key.\n"
            },
            "saslAwsSharedConfigFiles": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "List of paths to AWS shared config files.\n"
            },
            "saslAwsToken": {
                "type": "string",
                "description": "The AWS session token. Only required if you are using temporary security credentials.\n"
            },
            "saslMechanism": {
                "type": "string",
                "description": "SASL mechanism, can be plain, scram-sha512, scram-sha256, aws-iam\n"
            },
            "saslOauthScopes": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "OAuth scopes to request when using the oauthbearer mechanism\n"
            },
            "saslPassword": {
                "type": "string",
                "description": "Password for SASL authentication.\n"
            },
            "saslTokenUrl": {
                "type": "string",
                "description": "The url to retrieve oauth2 tokens from, when using sasl mechanism oauthbearer\n"
            },
            "saslUsername": {
                "type": "string",
                "description": "Username for SASL authentication.\n"
            },
            "skipTlsVerify": {
                "type": "boolean",
                "description": "Set this to true only if the target Kafka server is an insecure development instance.\n"
            },
            "timeout": {
                "type": "integer",
                "description": "Timeout in seconds\n"
            },
            "tlsEnabled": {
                "type": "boolean",
                "description": "Enable communication with the Kafka Cluster over TLS.\n"
            }
        },
        "required": [
            "bootstrapServers"
        ],
        "inputProperties": {
            "bootstrapServers": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "A list of kafka brokers\n"
            },
            "caCert": {
                "type": "string",
                "description": "CA certificate file to validate the server's certificate.\n"
            },
            "caCertFile": {
                "type": "string",
                "description": "Path to a CA certificate file to validate the server's certificate.\n",
                "deprecationMessage": "This parameter is now deprecated and will be removed in a later release, please use `ca_cert` instead."
            },
            "clientCert": {
                "type": "string",
                "description": "The client certificate.\n"
            },
            "clientCertFile": {
                "type": "string",
                "description": "Path to a file containing the client certificate.\n",
                "deprecationMessage": "This parameter is now deprecated and will be removed in a later release, please use `client_cert` instead."
            },
            "clientKey": {
                "type": "string",
                "description": "The private key that the certificate was issued for.\n"
            },
            "clientKeyFile": {
                "type": "string",
                "description": "Path to a file containing the private key that the certificate was issued for.\n",
                "deprecationMessage": "This parameter is now deprecated and will be removed in a later release, please use `client_key` instead."
            },
            "clientKeyPassphrase": {
                "type": "string",
                "description": "The passphrase for the private key that the certificate was issued for.\n"
            },
            "kafkaVersion": {
                "type": "string",
                "description": "The version of Kafka protocol to use in `$MAJOR.$MINOR.$PATCH` format. Some features may not be available on older\nversions. Default is 2.7.0.\n"
            },
            "saslAwsAccessKey": {
                "type": "string",
                "description": "The AWS access key.\n"
            },
            "saslAwsContainerAuthorizationTokenFile": {
                "type": "string",
                "description": "Path to a file containing the AWS pod identity authorization token\n"
            },
            "saslAwsContainerCredentialsFullUri": {
                "type": "string",
                "description": "URI to retrieve AWS credentials from\n"
            },
            "saslAwsCredsDebug": {
                "type": "boolean",
                "description": "Set this to true to turn AWS credentials debug.\n"
            },
            "saslAwsExternalId": {
                "type": "string",
                "description": "External ID of the AWS IAM role to assume\n"
            },
            "saslAwsProfile": {
                "type": "string",
                "description": "AWS profile name to use\n"
            },
            "saslAwsRegion": {
                "type": "string",
                "description": "AWS region where MSK is deployed.\n"
            },
            "saslAwsRoleArn": {
                "type": "string",
                "description": "Arn of an AWS IAM role to assume\n"
            },
            "saslAwsSecretKey": {
                "type": "string",
                "description": "The AWS secret key.\n"
            },
            "saslAwsSharedConfigFiles": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "List of paths to AWS shared config files.\n"
            },
            "saslAwsToken": {
                "type": "string",
                "description": "The AWS session token. Only required if you are using temporary security credentials.\n"
            },
            "saslMechanism": {
                "type": "string",
                "description": "SASL mechanism, can be plain, scram-sha512, scram-sha256, aws-iam\n",
                "default": "plain",
                "defaultInfo": {
                    "environment": [
                        "KAFKA_SASL_MECHANISM"
                    ]
                }
            },
            "saslOauthScopes": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "OAuth scopes to request when using the oauthbearer mechanism\n"
            },
            "saslPassword": {
                "type": "string",
                "description": "Password for SASL authentication.\n"
            },
            "saslTokenUrl": {
                "type": "string",
                "description": "The url to retrieve oauth2 tokens from, when using sasl mechanism oauthbearer\n"
            },
            "saslUsername": {
                "type": "string",
                "description": "Username for SASL authentication.\n"
            },
            "skipTlsVerify": {
                "type": "boolean",
                "description": "Set this to true only if the target Kafka server is an insecure development instance.\n",
                "default": false,
                "defaultInfo": {
                    "environment": [
                        "KAFKA_SKIP_VERIFY"
                    ]
                }
            },
            "timeout": {
                "type": "integer",
                "description": "Timeout in seconds\n"
            },
            "tlsEnabled": {
                "type": "boolean",
                "description": "Enable communication with the Kafka Cluster over TLS.\n",
                "default": true,
                "defaultInfo": {
                    "environment": [
                        "KAFKA_ENABLE_TLS"
                    ]
                }
            }
        },
        "requiredInputs": [
            "bootstrapServers"
        ],
        "methods": {
            "terraformConfig": "pulumi:providers:kafka/terraformConfig"
        }
    },
    "resources": {
        "kafka:index/acl:Acl": {
            "description": "The `kafka.Acl` resource manages Apache Kafka Access Control Lists (ACLs). ACLs control access to Kafka resources like topics, consumer groups, and clusters by defining which principals (users or services) can perform specific operations on these resources.\n\n## Example Usage\n\n### Allow Producer Access to Topic\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\nconst producer = new kafka.Acl(\"producer\", {\n    aclResourceName: \"orders\",\n    aclResourceType: \"Topic\",\n    aclPrincipal: \"User:producer-service\",\n    aclHost: \"*\",\n    aclOperation: \"Write\",\n    aclPermissionType: \"Allow\",\n});\n// Also grant describe permission for producers\nconst producerDescribe = new kafka.Acl(\"producer_describe\", {\n    aclResourceName: \"orders\",\n    aclResourceType: \"Topic\",\n    aclPrincipal: \"User:producer-service\",\n    aclHost: \"*\",\n    aclOperation: \"Describe\",\n    aclPermissionType: \"Allow\",\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\nproducer = kafka.Acl(\"producer\",\n    acl_resource_name=\"orders\",\n    acl_resource_type=\"Topic\",\n    acl_principal=\"User:producer-service\",\n    acl_host=\"*\",\n    acl_operation=\"Write\",\n    acl_permission_type=\"Allow\")\n# Also grant describe permission for producers\nproducer_describe = kafka.Acl(\"producer_describe\",\n    acl_resource_name=\"orders\",\n    acl_resource_type=\"Topic\",\n    acl_principal=\"User:producer-service\",\n    acl_host=\"*\",\n    acl_operation=\"Describe\",\n    acl_permission_type=\"Allow\")\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    var producer = new Kafka.Acl(\"producer\", new()\n    {\n        AclResourceName = \"orders\",\n        AclResourceType = \"Topic\",\n        AclPrincipal = \"User:producer-service\",\n        AclHost = \"*\",\n        AclOperation = \"Write\",\n        AclPermissionType = \"Allow\",\n    });\n\n    // Also grant describe permission for producers\n    var producerDescribe = new Kafka.Acl(\"producer_describe\", new()\n    {\n        AclResourceName = \"orders\",\n        AclResourceType = \"Topic\",\n        AclPrincipal = \"User:producer-service\",\n        AclHost = \"*\",\n        AclOperation = \"Describe\",\n        AclPermissionType = \"Allow\",\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t_, err := kafka.NewAcl(ctx, \"producer\", \u0026kafka.AclArgs{\n\t\t\tAclResourceName:   pulumi.String(\"orders\"),\n\t\t\tAclResourceType:   pulumi.String(\"Topic\"),\n\t\t\tAclPrincipal:      pulumi.String(\"User:producer-service\"),\n\t\t\tAclHost:           pulumi.String(\"*\"),\n\t\t\tAclOperation:      pulumi.String(\"Write\"),\n\t\t\tAclPermissionType: pulumi.String(\"Allow\"),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Also grant describe permission for producers\n\t\t_, err = kafka.NewAcl(ctx, \"producer_describe\", \u0026kafka.AclArgs{\n\t\t\tAclResourceName:   pulumi.String(\"orders\"),\n\t\t\tAclResourceType:   pulumi.String(\"Topic\"),\n\t\t\tAclPrincipal:      pulumi.String(\"User:producer-service\"),\n\t\t\tAclHost:           pulumi.String(\"*\"),\n\t\t\tAclOperation:      pulumi.String(\"Describe\"),\n\t\t\tAclPermissionType: pulumi.String(\"Allow\"),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Acl;\nimport com.pulumi.kafka.AclArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        var producer = new Acl(\"producer\", AclArgs.builder()\n            .aclResourceName(\"orders\")\n            .aclResourceType(\"Topic\")\n            .aclPrincipal(\"User:producer-service\")\n            .aclHost(\"*\")\n            .aclOperation(\"Write\")\n            .aclPermissionType(\"Allow\")\n            .build());\n\n        // Also grant describe permission for producers\n        var producerDescribe = new Acl(\"producerDescribe\", AclArgs.builder()\n            .aclResourceName(\"orders\")\n            .aclResourceType(\"Topic\")\n            .aclPrincipal(\"User:producer-service\")\n            .aclHost(\"*\")\n            .aclOperation(\"Describe\")\n            .aclPermissionType(\"Allow\")\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  producer:\n    type: kafka:Acl\n    properties:\n      aclResourceName: orders\n      aclResourceType: Topic\n      aclPrincipal: User:producer-service\n      aclHost: '*'\n      aclOperation: Write\n      aclPermissionType: Allow\n  # Also grant describe permission for producers\n  producerDescribe:\n    type: kafka:Acl\n    name: producer_describe\n    properties:\n      aclResourceName: orders\n      aclResourceType: Topic\n      aclPrincipal: User:producer-service\n      aclHost: '*'\n      aclOperation: Describe\n      aclPermissionType: Allow\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n### Allow Consumer Group Access\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\n// Allow read access to topic\nconst consumerRead = new kafka.Acl(\"consumer_read\", {\n    aclResourceName: \"orders\",\n    aclResourceType: \"Topic\",\n    aclPrincipal: \"User:consumer-service\",\n    aclHost: \"*\",\n    aclOperation: \"Read\",\n    aclPermissionType: \"Allow\",\n});\n// Allow access to consumer group\nconst consumerGroup = new kafka.Acl(\"consumer_group\", {\n    aclResourceName: \"order-processors\",\n    aclResourceType: \"Group\",\n    aclPrincipal: \"User:consumer-service\",\n    aclHost: \"*\",\n    aclOperation: \"Read\",\n    aclPermissionType: \"Allow\",\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\n# Allow read access to topic\nconsumer_read = kafka.Acl(\"consumer_read\",\n    acl_resource_name=\"orders\",\n    acl_resource_type=\"Topic\",\n    acl_principal=\"User:consumer-service\",\n    acl_host=\"*\",\n    acl_operation=\"Read\",\n    acl_permission_type=\"Allow\")\n# Allow access to consumer group\nconsumer_group = kafka.Acl(\"consumer_group\",\n    acl_resource_name=\"order-processors\",\n    acl_resource_type=\"Group\",\n    acl_principal=\"User:consumer-service\",\n    acl_host=\"*\",\n    acl_operation=\"Read\",\n    acl_permission_type=\"Allow\")\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    // Allow read access to topic\n    var consumerRead = new Kafka.Acl(\"consumer_read\", new()\n    {\n        AclResourceName = \"orders\",\n        AclResourceType = \"Topic\",\n        AclPrincipal = \"User:consumer-service\",\n        AclHost = \"*\",\n        AclOperation = \"Read\",\n        AclPermissionType = \"Allow\",\n    });\n\n    // Allow access to consumer group\n    var consumerGroup = new Kafka.Acl(\"consumer_group\", new()\n    {\n        AclResourceName = \"order-processors\",\n        AclResourceType = \"Group\",\n        AclPrincipal = \"User:consumer-service\",\n        AclHost = \"*\",\n        AclOperation = \"Read\",\n        AclPermissionType = \"Allow\",\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t// Allow read access to topic\n\t\t_, err := kafka.NewAcl(ctx, \"consumer_read\", \u0026kafka.AclArgs{\n\t\t\tAclResourceName:   pulumi.String(\"orders\"),\n\t\t\tAclResourceType:   pulumi.String(\"Topic\"),\n\t\t\tAclPrincipal:      pulumi.String(\"User:consumer-service\"),\n\t\t\tAclHost:           pulumi.String(\"*\"),\n\t\t\tAclOperation:      pulumi.String(\"Read\"),\n\t\t\tAclPermissionType: pulumi.String(\"Allow\"),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Allow access to consumer group\n\t\t_, err = kafka.NewAcl(ctx, \"consumer_group\", \u0026kafka.AclArgs{\n\t\t\tAclResourceName:   pulumi.String(\"order-processors\"),\n\t\t\tAclResourceType:   pulumi.String(\"Group\"),\n\t\t\tAclPrincipal:      pulumi.String(\"User:consumer-service\"),\n\t\t\tAclHost:           pulumi.String(\"*\"),\n\t\t\tAclOperation:      pulumi.String(\"Read\"),\n\t\t\tAclPermissionType: pulumi.String(\"Allow\"),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Acl;\nimport com.pulumi.kafka.AclArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        // Allow read access to topic\n        var consumerRead = new Acl(\"consumerRead\", AclArgs.builder()\n            .aclResourceName(\"orders\")\n            .aclResourceType(\"Topic\")\n            .aclPrincipal(\"User:consumer-service\")\n            .aclHost(\"*\")\n            .aclOperation(\"Read\")\n            .aclPermissionType(\"Allow\")\n            .build());\n\n        // Allow access to consumer group\n        var consumerGroup = new Acl(\"consumerGroup\", AclArgs.builder()\n            .aclResourceName(\"order-processors\")\n            .aclResourceType(\"Group\")\n            .aclPrincipal(\"User:consumer-service\")\n            .aclHost(\"*\")\n            .aclOperation(\"Read\")\n            .aclPermissionType(\"Allow\")\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  # Allow read access to topic\n  consumerRead:\n    type: kafka:Acl\n    name: consumer_read\n    properties:\n      aclResourceName: orders\n      aclResourceType: Topic\n      aclPrincipal: User:consumer-service\n      aclHost: '*'\n      aclOperation: Read\n      aclPermissionType: Allow\n  # Allow access to consumer group\n  consumerGroup:\n    type: kafka:Acl\n    name: consumer_group\n    properties:\n      aclResourceName: order-processors\n      aclResourceType: Group\n      aclPrincipal: User:consumer-service\n      aclHost: '*'\n      aclOperation: Read\n      aclPermissionType: Allow\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n### Prefix-Based Access Control\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\n// Grant access to all topics with prefix \"logs-\"\nconst logsAccess = new kafka.Acl(\"logs_access\", {\n    aclResourceName: \"logs-\",\n    aclResourceType: \"Topic\",\n    resourcePatternTypeFilter: \"Prefixed\",\n    aclPrincipal: \"User:log-aggregator\",\n    aclHost: \"*\",\n    aclOperation: \"Read\",\n    aclPermissionType: \"Allow\",\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\n# Grant access to all topics with prefix \"logs-\"\nlogs_access = kafka.Acl(\"logs_access\",\n    acl_resource_name=\"logs-\",\n    acl_resource_type=\"Topic\",\n    resource_pattern_type_filter=\"Prefixed\",\n    acl_principal=\"User:log-aggregator\",\n    acl_host=\"*\",\n    acl_operation=\"Read\",\n    acl_permission_type=\"Allow\")\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    // Grant access to all topics with prefix \"logs-\"\n    var logsAccess = new Kafka.Acl(\"logs_access\", new()\n    {\n        AclResourceName = \"logs-\",\n        AclResourceType = \"Topic\",\n        ResourcePatternTypeFilter = \"Prefixed\",\n        AclPrincipal = \"User:log-aggregator\",\n        AclHost = \"*\",\n        AclOperation = \"Read\",\n        AclPermissionType = \"Allow\",\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t// Grant access to all topics with prefix \"logs-\"\n\t\t_, err := kafka.NewAcl(ctx, \"logs_access\", \u0026kafka.AclArgs{\n\t\t\tAclResourceName:           pulumi.String(\"logs-\"),\n\t\t\tAclResourceType:           pulumi.String(\"Topic\"),\n\t\t\tResourcePatternTypeFilter: pulumi.String(\"Prefixed\"),\n\t\t\tAclPrincipal:              pulumi.String(\"User:log-aggregator\"),\n\t\t\tAclHost:                   pulumi.String(\"*\"),\n\t\t\tAclOperation:              pulumi.String(\"Read\"),\n\t\t\tAclPermissionType:         pulumi.String(\"Allow\"),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Acl;\nimport com.pulumi.kafka.AclArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        // Grant access to all topics with prefix \"logs-\"\n        var logsAccess = new Acl(\"logsAccess\", AclArgs.builder()\n            .aclResourceName(\"logs-\")\n            .aclResourceType(\"Topic\")\n            .resourcePatternTypeFilter(\"Prefixed\")\n            .aclPrincipal(\"User:log-aggregator\")\n            .aclHost(\"*\")\n            .aclOperation(\"Read\")\n            .aclPermissionType(\"Allow\")\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  # Grant access to all topics with prefix \"logs-\"\n  logsAccess:\n    type: kafka:Acl\n    name: logs_access\n    properties:\n      aclResourceName: logs-\n      aclResourceType: Topic\n      resourcePatternTypeFilter: Prefixed\n      aclPrincipal: User:log-aggregator\n      aclHost: '*'\n      aclOperation: Read\n      aclPermissionType: Allow\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n### Admin User with Full Access\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\n// Grant cluster-level admin access\nconst adminCluster = new kafka.Acl(\"admin_cluster\", {\n    aclResourceName: \"kafka-cluster\",\n    aclResourceType: \"Cluster\",\n    aclPrincipal: \"User:admin\",\n    aclHost: \"*\",\n    aclOperation: \"All\",\n    aclPermissionType: \"Allow\",\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\n# Grant cluster-level admin access\nadmin_cluster = kafka.Acl(\"admin_cluster\",\n    acl_resource_name=\"kafka-cluster\",\n    acl_resource_type=\"Cluster\",\n    acl_principal=\"User:admin\",\n    acl_host=\"*\",\n    acl_operation=\"All\",\n    acl_permission_type=\"Allow\")\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    // Grant cluster-level admin access\n    var adminCluster = new Kafka.Acl(\"admin_cluster\", new()\n    {\n        AclResourceName = \"kafka-cluster\",\n        AclResourceType = \"Cluster\",\n        AclPrincipal = \"User:admin\",\n        AclHost = \"*\",\n        AclOperation = \"All\",\n        AclPermissionType = \"Allow\",\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t// Grant cluster-level admin access\n\t\t_, err := kafka.NewAcl(ctx, \"admin_cluster\", \u0026kafka.AclArgs{\n\t\t\tAclResourceName:   pulumi.String(\"kafka-cluster\"),\n\t\t\tAclResourceType:   pulumi.String(\"Cluster\"),\n\t\t\tAclPrincipal:      pulumi.String(\"User:admin\"),\n\t\t\tAclHost:           pulumi.String(\"*\"),\n\t\t\tAclOperation:      pulumi.String(\"All\"),\n\t\t\tAclPermissionType: pulumi.String(\"Allow\"),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Acl;\nimport com.pulumi.kafka.AclArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        // Grant cluster-level admin access\n        var adminCluster = new Acl(\"adminCluster\", AclArgs.builder()\n            .aclResourceName(\"kafka-cluster\")\n            .aclResourceType(\"Cluster\")\n            .aclPrincipal(\"User:admin\")\n            .aclHost(\"*\")\n            .aclOperation(\"All\")\n            .aclPermissionType(\"Allow\")\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  # Grant cluster-level admin access\n  adminCluster:\n    type: kafka:Acl\n    name: admin_cluster\n    properties:\n      aclResourceName: kafka-cluster\n      aclResourceType: Cluster\n      aclPrincipal: User:admin\n      aclHost: '*'\n      aclOperation: All\n      aclPermissionType: Allow\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n## Common ACL Patterns\n\n### Producer ACLs\nProducers typically need:\n- `Write` and `Describe` on topics\n- `Write` on `TransactionalID` (for transactional producers)\n- `IdempotentWrite` on `Cluster` (for idempotent producers)\n\n### Consumer ACLs\nConsumers typically need:\n- `Read` on topics\n- `Read` on consumer groups\n- `Describe` on topics (optional, for metadata)\n\n### Admin ACLs\nAdministrators typically need:\n- `All` on `Cluster`\n- Or specific operations like `Alter`, `AlterConfigs`, `Create`, `Delete`\n\n\u003e **Warning:** Be cautious with `Deny` ACLs as they take precedence over `Allow` ACLs. A deny rule will block access even if an allow rule exists.\n\n## Import\n\nKafka ACLs can be imported using a pipe-delimited string containing all ACL properties:\n\nFormat: ${acl_principal}|${acl_host}|${acl_operation}|${acl_permission_type}|${resource_type}|${resource_name}|${resource_pattern_type_filter}\n\n```sh\n$ pulumi import kafka:index/acl:Acl example 'User:producer|*|Write|Allow|Topic|orders|Literal'\n```\n\n",
            "properties": {
                "aclHost": {
                    "type": "string"
                },
                "aclOperation": {
                    "type": "string"
                },
                "aclPermissionType": {
                    "type": "string"
                },
                "aclPrincipal": {
                    "type": "string"
                },
                "aclResourceName": {
                    "type": "string",
                    "description": "The name of the resource\n"
                },
                "aclResourceType": {
                    "type": "string"
                },
                "resourcePatternTypeFilter": {
                    "type": "string"
                }
            },
            "required": [
                "aclHost",
                "aclOperation",
                "aclPermissionType",
                "aclPrincipal",
                "aclResourceName",
                "aclResourceType"
            ],
            "inputProperties": {
                "aclHost": {
                    "type": "string",
                    "willReplaceOnChanges": true
                },
                "aclOperation": {
                    "type": "string",
                    "willReplaceOnChanges": true
                },
                "aclPermissionType": {
                    "type": "string",
                    "willReplaceOnChanges": true
                },
                "aclPrincipal": {
                    "type": "string",
                    "willReplaceOnChanges": true
                },
                "aclResourceName": {
                    "type": "string",
                    "description": "The name of the resource\n",
                    "willReplaceOnChanges": true
                },
                "aclResourceType": {
                    "type": "string",
                    "willReplaceOnChanges": true
                },
                "resourcePatternTypeFilter": {
                    "type": "string",
                    "willReplaceOnChanges": true
                }
            },
            "requiredInputs": [
                "aclHost",
                "aclOperation",
                "aclPermissionType",
                "aclPrincipal",
                "aclResourceName",
                "aclResourceType"
            ],
            "stateInputs": {
                "description": "Input properties used for looking up and filtering Acl resources.\n",
                "properties": {
                    "aclHost": {
                        "type": "string",
                        "willReplaceOnChanges": true
                    },
                    "aclOperation": {
                        "type": "string",
                        "willReplaceOnChanges": true
                    },
                    "aclPermissionType": {
                        "type": "string",
                        "willReplaceOnChanges": true
                    },
                    "aclPrincipal": {
                        "type": "string",
                        "willReplaceOnChanges": true
                    },
                    "aclResourceName": {
                        "type": "string",
                        "description": "The name of the resource\n",
                        "willReplaceOnChanges": true
                    },
                    "aclResourceType": {
                        "type": "string",
                        "willReplaceOnChanges": true
                    },
                    "resourcePatternTypeFilter": {
                        "type": "string",
                        "willReplaceOnChanges": true
                    }
                },
                "type": "object"
            }
        },
        "kafka:index/quota:Quota": {
            "description": "The `kafka.Quota` resource manages Kafka quotas, which are used to limit resource usage and prevent any single client from monopolizing broker resources. Quotas can be applied to clients, users, or IP addresses to control bandwidth and request rates.\n\n## Example Usage\n\n### Client ID Quota\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\n// Limit a specific client's bandwidth\nconst mobileApp = new kafka.Quota(\"mobile_app\", {\n    entityName: \"mobile-app-v1\",\n    entityType: \"client-id\",\n    config: {\n        consumer_byte_rate: \"5000000\",\n        producer_byte_rate: \"2500000\",\n        request_percentage: \"200\",\n    },\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\n# Limit a specific client's bandwidth\nmobile_app = kafka.Quota(\"mobile_app\",\n    entity_name=\"mobile-app-v1\",\n    entity_type=\"client-id\",\n    config={\n        \"consumer_byte_rate\": \"5000000\",\n        \"producer_byte_rate\": \"2500000\",\n        \"request_percentage\": \"200\",\n    })\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    // Limit a specific client's bandwidth\n    var mobileApp = new Kafka.Quota(\"mobile_app\", new()\n    {\n        EntityName = \"mobile-app-v1\",\n        EntityType = \"client-id\",\n        Config = \n        {\n            { \"consumer_byte_rate\", \"5000000\" },\n            { \"producer_byte_rate\", \"2500000\" },\n            { \"request_percentage\", \"200\" },\n        },\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t// Limit a specific client's bandwidth\n\t\t_, err := kafka.NewQuota(ctx, \"mobile_app\", \u0026kafka.QuotaArgs{\n\t\t\tEntityName: pulumi.String(\"mobile-app-v1\"),\n\t\t\tEntityType: pulumi.String(\"client-id\"),\n\t\t\tConfig: pulumi.StringMap{\n\t\t\t\t\"consumer_byte_rate\": pulumi.String(\"5000000\"),\n\t\t\t\t\"producer_byte_rate\": pulumi.String(\"2500000\"),\n\t\t\t\t\"request_percentage\": pulumi.String(\"200\"),\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Quota;\nimport com.pulumi.kafka.QuotaArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        // Limit a specific client's bandwidth\n        var mobileApp = new Quota(\"mobileApp\", QuotaArgs.builder()\n            .entityName(\"mobile-app-v1\")\n            .entityType(\"client-id\")\n            .config(Map.ofEntries(\n                Map.entry(\"consumer_byte_rate\", \"5000000\"),\n                Map.entry(\"producer_byte_rate\", \"2500000\"),\n                Map.entry(\"request_percentage\", \"200\")\n            ))\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  # Limit a specific client's bandwidth\n  mobileApp:\n    type: kafka:Quota\n    name: mobile_app\n    properties:\n      entityName: mobile-app-v1\n      entityType: client-id\n      config:\n        consumer_byte_rate: '5000000'\n        producer_byte_rate: '2500000'\n        request_percentage: '200'\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n### User Quota\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\n// Set quotas for a specific user\nconst serviceAccount = new kafka.Quota(\"service_account\", {\n    entityName: \"payment-service\",\n    entityType: \"user\",\n    config: {\n        consumer_byte_rate: \"10000000\",\n        producer_byte_rate: \"10000000\",\n        request_percentage: \"400\",\n    },\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\n# Set quotas for a specific user\nservice_account = kafka.Quota(\"service_account\",\n    entity_name=\"payment-service\",\n    entity_type=\"user\",\n    config={\n        \"consumer_byte_rate\": \"10000000\",\n        \"producer_byte_rate\": \"10000000\",\n        \"request_percentage\": \"400\",\n    })\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    // Set quotas for a specific user\n    var serviceAccount = new Kafka.Quota(\"service_account\", new()\n    {\n        EntityName = \"payment-service\",\n        EntityType = \"user\",\n        Config = \n        {\n            { \"consumer_byte_rate\", \"10000000\" },\n            { \"producer_byte_rate\", \"10000000\" },\n            { \"request_percentage\", \"400\" },\n        },\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t// Set quotas for a specific user\n\t\t_, err := kafka.NewQuota(ctx, \"service_account\", \u0026kafka.QuotaArgs{\n\t\t\tEntityName: pulumi.String(\"payment-service\"),\n\t\t\tEntityType: pulumi.String(\"user\"),\n\t\t\tConfig: pulumi.StringMap{\n\t\t\t\t\"consumer_byte_rate\": pulumi.String(\"10000000\"),\n\t\t\t\t\"producer_byte_rate\": pulumi.String(\"10000000\"),\n\t\t\t\t\"request_percentage\": pulumi.String(\"400\"),\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Quota;\nimport com.pulumi.kafka.QuotaArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        // Set quotas for a specific user\n        var serviceAccount = new Quota(\"serviceAccount\", QuotaArgs.builder()\n            .entityName(\"payment-service\")\n            .entityType(\"user\")\n            .config(Map.ofEntries(\n                Map.entry(\"consumer_byte_rate\", \"10000000\"),\n                Map.entry(\"producer_byte_rate\", \"10000000\"),\n                Map.entry(\"request_percentage\", \"400\")\n            ))\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  # Set quotas for a specific user\n  serviceAccount:\n    type: kafka:Quota\n    name: service_account\n    properties:\n      entityName: payment-service\n      entityType: user\n      config:\n        consumer_byte_rate: '10000000'\n        producer_byte_rate: '10000000'\n        request_percentage: '400'\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n### Default User Quota\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\n// Set default quotas for all users (when entity_name is omitted)\nconst defaultUser = new kafka.Quota(\"default_user\", {\n    entityType: \"user\",\n    config: {\n        consumer_byte_rate: \"2000000\",\n        producer_byte_rate: \"1000000\",\n        request_percentage: \"100\",\n    },\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\n# Set default quotas for all users (when entity_name is omitted)\ndefault_user = kafka.Quota(\"default_user\",\n    entity_type=\"user\",\n    config={\n        \"consumer_byte_rate\": \"2000000\",\n        \"producer_byte_rate\": \"1000000\",\n        \"request_percentage\": \"100\",\n    })\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    // Set default quotas for all users (when entity_name is omitted)\n    var defaultUser = new Kafka.Quota(\"default_user\", new()\n    {\n        EntityType = \"user\",\n        Config = \n        {\n            { \"consumer_byte_rate\", \"2000000\" },\n            { \"producer_byte_rate\", \"1000000\" },\n            { \"request_percentage\", \"100\" },\n        },\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t// Set default quotas for all users (when entity_name is omitted)\n\t\t_, err := kafka.NewQuota(ctx, \"default_user\", \u0026kafka.QuotaArgs{\n\t\t\tEntityType: pulumi.String(\"user\"),\n\t\t\tConfig: pulumi.StringMap{\n\t\t\t\t\"consumer_byte_rate\": pulumi.String(\"2000000\"),\n\t\t\t\t\"producer_byte_rate\": pulumi.String(\"1000000\"),\n\t\t\t\t\"request_percentage\": pulumi.String(\"100\"),\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Quota;\nimport com.pulumi.kafka.QuotaArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        // Set default quotas for all users (when entity_name is omitted)\n        var defaultUser = new Quota(\"defaultUser\", QuotaArgs.builder()\n            .entityType(\"user\")\n            .config(Map.ofEntries(\n                Map.entry(\"consumer_byte_rate\", \"2000000\"),\n                Map.entry(\"producer_byte_rate\", \"1000000\"),\n                Map.entry(\"request_percentage\", \"100\")\n            ))\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  # Set default quotas for all users (when entity_name is omitted)\n  defaultUser:\n    type: kafka:Quota\n    name: default_user\n    properties:\n      entityType: user\n      config:\n        consumer_byte_rate: '2000000'\n        producer_byte_rate: '1000000'\n        request_percentage: '100'\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n### IP Address Quota\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\n// Rate limit connections from a specific IP\nconst externalIp = new kafka.Quota(\"external_ip\", {\n    entityName: \"203.0.113.0\",\n    entityType: \"ip\",\n    config: {\n        connection_creation_rate: \"10\",\n    },\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\n# Rate limit connections from a specific IP\nexternal_ip = kafka.Quota(\"external_ip\",\n    entity_name=\"203.0.113.0\",\n    entity_type=\"ip\",\n    config={\n        \"connection_creation_rate\": \"10\",\n    })\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    // Rate limit connections from a specific IP\n    var externalIp = new Kafka.Quota(\"external_ip\", new()\n    {\n        EntityName = \"203.0.113.0\",\n        EntityType = \"ip\",\n        Config = \n        {\n            { \"connection_creation_rate\", \"10\" },\n        },\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t// Rate limit connections from a specific IP\n\t\t_, err := kafka.NewQuota(ctx, \"external_ip\", \u0026kafka.QuotaArgs{\n\t\t\tEntityName: pulumi.String(\"203.0.113.0\"),\n\t\t\tEntityType: pulumi.String(\"ip\"),\n\t\t\tConfig: pulumi.StringMap{\n\t\t\t\t\"connection_creation_rate\": pulumi.String(\"10\"),\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Quota;\nimport com.pulumi.kafka.QuotaArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        // Rate limit connections from a specific IP\n        var externalIp = new Quota(\"externalIp\", QuotaArgs.builder()\n            .entityName(\"203.0.113.0\")\n            .entityType(\"ip\")\n            .config(Map.of(\"connection_creation_rate\", \"10\"))\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  # Rate limit connections from a specific IP\n  externalIp:\n    type: kafka:Quota\n    name: external_ip\n    properties:\n      entityName: 203.0.113.0\n      entityType: ip\n      config:\n        connection_creation_rate: '10'\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n## Quota Configuration Options\n\n### Bandwidth Quotas\n- `producer_byte_rate` - The maximum bytes per second that can be produced by the entity\n- `consumer_byte_rate` - The maximum bytes per second that can be consumed by the entity\n\n### Request Rate Quotas\n- `request_percentage` - The percentage of CPU time on each broker that the entity can use for requests. Values \u003e 100% indicate multiple CPUs (e.g., 200% = 2 CPUs)\n\n### Connection Quotas (IP-based only)\n- `connection_creation_rate` - The maximum rate of new connections per second from the IP address\n\n## Quota Precedence\n\nWhen multiple quotas apply to a request, Kafka uses the most specific quota:\n\n1. `/config/users/\u003cuser\u003e/clients/\u003cclient-id\u003e` (most specific)\n2. `/config/users/\u003cuser\u003e/clients/\u003cdefault\u003e`\n3. `/config/users/\u003cuser\u003e`\n4. `/config/users/\u003cdefault\u003e/clients/\u003cclient-id\u003e`\n5. `/config/users/\u003cdefault\u003e/clients/\u003cdefault\u003e`\n6. `/config/users/\u003cdefault\u003e` (least specific)\n\n## Best Practices\n\n1. **Start with Conservative Defaults**: Set reasonable default quotas for all users/clients and then create specific quotas for services that need higher limits.\n\n2. **Monitor Quota Usage**: Use Kafka metrics to monitor quota utilization and adjust as needed. Look for throttling metrics to identify when quotas are being hit.\n\n3. **Use Request Percentage Carefully**: The `request_percentage` quota affects CPU usage. Values over 100% mean the client can use more than one CPU core.\n\n4. **Plan for Growth**: Set quotas with some headroom to accommodate traffic growth, but not so high that a misbehaving client can impact the cluster.\n\n5. **Different Quotas for Different Environments**: Use stricter quotas in development/staging environments compared to production.\n\n\u003e **Note:** Quotas are applied immediately but may take a few seconds to propagate across all brokers.\n\n## Import\n\nKafka quotas can be imported using the entity type and name:\n\nFor named entities\n\n```sh\n$ pulumi import kafka:index/quota:Quota example client-id:my-client\n```\n\nFor default quotas (no entity name)\n\n```sh\n$ pulumi import kafka:index/quota:Quota default_user user:\n```\n\n",
            "properties": {
                "config": {
                    "type": "object",
                    "additionalProperties": {
                        "type": "string"
                    },
                    "description": "A map of string k/v properties.\n"
                },
                "entityName": {
                    "type": "string",
                    "description": "The name of the entity (if entity_name is not provided, it will create entity-default Kafka quota)\n"
                },
                "entityType": {
                    "type": "string",
                    "description": "The type of the entity (client-id, user, ip)\n"
                }
            },
            "required": [
                "entityType"
            ],
            "inputProperties": {
                "config": {
                    "type": "object",
                    "additionalProperties": {
                        "type": "string"
                    },
                    "description": "A map of string k/v properties.\n",
                    "willReplaceOnChanges": true
                },
                "entityName": {
                    "type": "string",
                    "description": "The name of the entity (if entity_name is not provided, it will create entity-default Kafka quota)\n",
                    "willReplaceOnChanges": true
                },
                "entityType": {
                    "type": "string",
                    "description": "The type of the entity (client-id, user, ip)\n",
                    "willReplaceOnChanges": true
                }
            },
            "requiredInputs": [
                "entityType"
            ],
            "stateInputs": {
                "description": "Input properties used for looking up and filtering Quota resources.\n",
                "properties": {
                    "config": {
                        "type": "object",
                        "additionalProperties": {
                            "type": "string"
                        },
                        "description": "A map of string k/v properties.\n",
                        "willReplaceOnChanges": true
                    },
                    "entityName": {
                        "type": "string",
                        "description": "The name of the entity (if entity_name is not provided, it will create entity-default Kafka quota)\n",
                        "willReplaceOnChanges": true
                    },
                    "entityType": {
                        "type": "string",
                        "description": "The type of the entity (client-id, user, ip)\n",
                        "willReplaceOnChanges": true
                    }
                },
                "type": "object"
            }
        },
        "kafka:index/topic:Topic": {
            "description": "The `kafka.Topic` resource manages Apache Kafka topics, including their partition count, replication factor, and various configuration parameters. This resource supports non-destructive partition count increases.\n\n## Example Usage\n\n### Basic Topic\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\nconst example = new kafka.Topic(\"example\", {\n    name: \"example-topic\",\n    replicationFactor: 3,\n    partitions: 10,\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\nexample = kafka.Topic(\"example\",\n    name=\"example-topic\",\n    replication_factor=3,\n    partitions=10)\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    var example = new Kafka.Topic(\"example\", new()\n    {\n        Name = \"example-topic\",\n        ReplicationFactor = 3,\n        Partitions = 10,\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t_, err := kafka.NewTopic(ctx, \"example\", \u0026kafka.TopicArgs{\n\t\t\tName:              pulumi.String(\"example-topic\"),\n\t\t\tReplicationFactor: pulumi.Int(3),\n\t\t\tPartitions:        pulumi.Int(10),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Topic;\nimport com.pulumi.kafka.TopicArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        var example = new Topic(\"example\", TopicArgs.builder()\n            .name(\"example-topic\")\n            .replicationFactor(3)\n            .partitions(10)\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  example:\n    type: kafka:Topic\n    properties:\n      name: example-topic\n      replicationFactor: 3\n      partitions: 10\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n### Topic with Common Configurations\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\nconst logs = new kafka.Topic(\"logs\", {\n    name: \"application-logs\",\n    replicationFactor: 3,\n    partitions: 50,\n    config: {\n        \"retention.ms\": \"604800000\",\n        \"segment.ms\": \"86400000\",\n        \"cleanup.policy\": \"delete\",\n        \"compression.type\": \"gzip\",\n    },\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\nlogs = kafka.Topic(\"logs\",\n    name=\"application-logs\",\n    replication_factor=3,\n    partitions=50,\n    config={\n        \"retention.ms\": \"604800000\",\n        \"segment.ms\": \"86400000\",\n        \"cleanup.policy\": \"delete\",\n        \"compression.type\": \"gzip\",\n    })\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    var logs = new Kafka.Topic(\"logs\", new()\n    {\n        Name = \"application-logs\",\n        ReplicationFactor = 3,\n        Partitions = 50,\n        Config = \n        {\n            { \"retention.ms\", \"604800000\" },\n            { \"segment.ms\", \"86400000\" },\n            { \"cleanup.policy\", \"delete\" },\n            { \"compression.type\", \"gzip\" },\n        },\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t_, err := kafka.NewTopic(ctx, \"logs\", \u0026kafka.TopicArgs{\n\t\t\tName:              pulumi.String(\"application-logs\"),\n\t\t\tReplicationFactor: pulumi.Int(3),\n\t\t\tPartitions:        pulumi.Int(50),\n\t\t\tConfig: pulumi.StringMap{\n\t\t\t\t\"retention.ms\":     pulumi.String(\"604800000\"),\n\t\t\t\t\"segment.ms\":       pulumi.String(\"86400000\"),\n\t\t\t\t\"cleanup.policy\":   pulumi.String(\"delete\"),\n\t\t\t\t\"compression.type\": pulumi.String(\"gzip\"),\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Topic;\nimport com.pulumi.kafka.TopicArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        var logs = new Topic(\"logs\", TopicArgs.builder()\n            .name(\"application-logs\")\n            .replicationFactor(3)\n            .partitions(50)\n            .config(Map.ofEntries(\n                Map.entry(\"retention.ms\", \"604800000\"),\n                Map.entry(\"segment.ms\", \"86400000\"),\n                Map.entry(\"cleanup.policy\", \"delete\"),\n                Map.entry(\"compression.type\", \"gzip\")\n            ))\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  logs:\n    type: kafka:Topic\n    properties:\n      name: application-logs\n      replicationFactor: 3\n      partitions: 50\n      config:\n        retention.ms: '604800000'\n        segment.ms: '86400000'\n        cleanup.policy: delete\n        compression.type: gzip\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n### Compacted Topic for Event Sourcing\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\nconst events = new kafka.Topic(\"events\", {\n    name: \"user-events\",\n    replicationFactor: 3,\n    partitions: 100,\n    config: {\n        \"cleanup.policy\": \"compact\",\n        \"retention.ms\": \"-1\",\n        \"min.compaction.lag.ms\": \"3600000\",\n        \"delete.retention.ms\": \"86400000\",\n        \"compression.type\": \"lz4\",\n        \"segment.bytes\": \"1073741824\",\n    },\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\nevents = kafka.Topic(\"events\",\n    name=\"user-events\",\n    replication_factor=3,\n    partitions=100,\n    config={\n        \"cleanup.policy\": \"compact\",\n        \"retention.ms\": \"-1\",\n        \"min.compaction.lag.ms\": \"3600000\",\n        \"delete.retention.ms\": \"86400000\",\n        \"compression.type\": \"lz4\",\n        \"segment.bytes\": \"1073741824\",\n    })\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    var events = new Kafka.Topic(\"events\", new()\n    {\n        Name = \"user-events\",\n        ReplicationFactor = 3,\n        Partitions = 100,\n        Config = \n        {\n            { \"cleanup.policy\", \"compact\" },\n            { \"retention.ms\", \"-1\" },\n            { \"min.compaction.lag.ms\", \"3600000\" },\n            { \"delete.retention.ms\", \"86400000\" },\n            { \"compression.type\", \"lz4\" },\n            { \"segment.bytes\", \"1073741824\" },\n        },\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t_, err := kafka.NewTopic(ctx, \"events\", \u0026kafka.TopicArgs{\n\t\t\tName:              pulumi.String(\"user-events\"),\n\t\t\tReplicationFactor: pulumi.Int(3),\n\t\t\tPartitions:        pulumi.Int(100),\n\t\t\tConfig: pulumi.StringMap{\n\t\t\t\t\"cleanup.policy\":        pulumi.String(\"compact\"),\n\t\t\t\t\"retention.ms\":          pulumi.String(\"-1\"),\n\t\t\t\t\"min.compaction.lag.ms\": pulumi.String(\"3600000\"),\n\t\t\t\t\"delete.retention.ms\":   pulumi.String(\"86400000\"),\n\t\t\t\t\"compression.type\":      pulumi.String(\"lz4\"),\n\t\t\t\t\"segment.bytes\":         pulumi.String(\"1073741824\"),\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Topic;\nimport com.pulumi.kafka.TopicArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        var events = new Topic(\"events\", TopicArgs.builder()\n            .name(\"user-events\")\n            .replicationFactor(3)\n            .partitions(100)\n            .config(Map.ofEntries(\n                Map.entry(\"cleanup.policy\", \"compact\"),\n                Map.entry(\"retention.ms\", \"-1\"),\n                Map.entry(\"min.compaction.lag.ms\", \"3600000\"),\n                Map.entry(\"delete.retention.ms\", \"86400000\"),\n                Map.entry(\"compression.type\", \"lz4\"),\n                Map.entry(\"segment.bytes\", \"1073741824\")\n            ))\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  events:\n    type: kafka:Topic\n    properties:\n      name: user-events\n      replicationFactor: 3\n      partitions: 100\n      config:\n        cleanup.policy: compact\n        retention.ms: '-1'\n        min.compaction.lag.ms: '3600000'\n        delete.retention.ms: '86400000'\n        compression.type: lz4\n        segment.bytes: '1073741824'\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n### High-Throughput Topic\n\n\u003c!--Start PulumiCodeChooser --\u003e\n```typescript\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as kafka from \"@pulumi/kafka\";\n\nconst metrics = new kafka.Topic(\"metrics\", {\n    name: \"system-metrics\",\n    replicationFactor: 2,\n    partitions: 200,\n    config: {\n        \"retention.ms\": \"86400000\",\n        \"segment.ms\": \"3600000\",\n        \"compression.type\": \"lz4\",\n        \"max.message.bytes\": \"1048576\",\n        \"min.insync.replicas\": \"2\",\n        \"unclean.leader.election.enable\": \"false\",\n    },\n});\n```\n```python\nimport pulumi\nimport pulumi_kafka as kafka\n\nmetrics = kafka.Topic(\"metrics\",\n    name=\"system-metrics\",\n    replication_factor=2,\n    partitions=200,\n    config={\n        \"retention.ms\": \"86400000\",\n        \"segment.ms\": \"3600000\",\n        \"compression.type\": \"lz4\",\n        \"max.message.bytes\": \"1048576\",\n        \"min.insync.replicas\": \"2\",\n        \"unclean.leader.election.enable\": \"false\",\n    })\n```\n```csharp\nusing System.Collections.Generic;\nusing System.Linq;\nusing Pulumi;\nusing Kafka = Pulumi.Kafka;\n\nreturn await Deployment.RunAsync(() =\u003e \n{\n    var metrics = new Kafka.Topic(\"metrics\", new()\n    {\n        Name = \"system-metrics\",\n        ReplicationFactor = 2,\n        Partitions = 200,\n        Config = \n        {\n            { \"retention.ms\", \"86400000\" },\n            { \"segment.ms\", \"3600000\" },\n            { \"compression.type\", \"lz4\" },\n            { \"max.message.bytes\", \"1048576\" },\n            { \"min.insync.replicas\", \"2\" },\n            { \"unclean.leader.election.enable\", \"false\" },\n        },\n    });\n\n});\n```\n```go\npackage main\n\nimport (\n\t\"github.com/pulumi/pulumi-kafka/sdk/v3/go/kafka\"\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\nfunc main() {\n\tpulumi.Run(func(ctx *pulumi.Context) error {\n\t\t_, err := kafka.NewTopic(ctx, \"metrics\", \u0026kafka.TopicArgs{\n\t\t\tName:              pulumi.String(\"system-metrics\"),\n\t\t\tReplicationFactor: pulumi.Int(2),\n\t\t\tPartitions:        pulumi.Int(200),\n\t\t\tConfig: pulumi.StringMap{\n\t\t\t\t\"retention.ms\":                   pulumi.String(\"86400000\"),\n\t\t\t\t\"segment.ms\":                     pulumi.String(\"3600000\"),\n\t\t\t\t\"compression.type\":               pulumi.String(\"lz4\"),\n\t\t\t\t\"max.message.bytes\":              pulumi.String(\"1048576\"),\n\t\t\t\t\"min.insync.replicas\":            pulumi.String(\"2\"),\n\t\t\t\t\"unclean.leader.election.enable\": pulumi.String(\"false\"),\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n}\n```\n```java\npackage generated_program;\n\nimport com.pulumi.Context;\nimport com.pulumi.Pulumi;\nimport com.pulumi.core.Output;\nimport com.pulumi.kafka.Topic;\nimport com.pulumi.kafka.TopicArgs;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Map;\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\npublic class App {\n    public static void main(String[] args) {\n        Pulumi.run(App::stack);\n    }\n\n    public static void stack(Context ctx) {\n        var metrics = new Topic(\"metrics\", TopicArgs.builder()\n            .name(\"system-metrics\")\n            .replicationFactor(2)\n            .partitions(200)\n            .config(Map.ofEntries(\n                Map.entry(\"retention.ms\", \"86400000\"),\n                Map.entry(\"segment.ms\", \"3600000\"),\n                Map.entry(\"compression.type\", \"lz4\"),\n                Map.entry(\"max.message.bytes\", \"1048576\"),\n                Map.entry(\"min.insync.replicas\", \"2\"),\n                Map.entry(\"unclean.leader.election.enable\", \"false\")\n            ))\n            .build());\n\n    }\n}\n```\n```yaml\nresources:\n  metrics:\n    type: kafka:Topic\n    properties:\n      name: system-metrics\n      replicationFactor: 2\n      partitions: 200\n      config:\n        retention.ms: '86400000'\n        segment.ms: '3600000'\n        compression.type: lz4\n        max.message.bytes: '1048576'\n        min.insync.replicas: '2'\n        unclean.leader.election.enable: 'false'\n```\n\u003c!--End PulumiCodeChooser --\u003e\n\n## Configuration Parameters\n\nThe `config` map supports all Kafka topic-level configurations. Common configurations include:\n\n### Retention Settings\n- `retention.ms` - How long to retain messages (in milliseconds). Default: 604800000 (7 days)\n- `retention.bytes` - Maximum size of the log before deleting old segments. Default: -1 (no limit)\n- `segment.ms` - Time after which a log segment should be rotated. Default: 604800000 (7 days)\n- `segment.bytes` - Maximum size of a single log segment file. Default: 1073741824 (1GB)\n\n### Cleanup and Compaction\n- `cleanup.policy` - Either \"delete\" or \"compact\" or both \"compact,delete\". Default: \"delete\"\n- `min.compaction.lag.ms` - Minimum time a message will remain uncompacted. Default: 0\n- `delete.retention.ms` - How long to retain delete tombstone markers for compacted topics. Default: 86400000 (1 day)\n\n### Compression\n- `compression.type` - Compression codec: \"uncompressed\", \"zstd\", \"lz4\", \"snappy\", \"gzip\", \"producer\". Default: \"producer\"\n\n### Replication and Durability\n- `min.insync.replicas` - Minimum number of replicas that must acknowledge a write. Default: 1\n- `unclean.leader.election.enable` - Whether to allow replicas not in ISR to be elected leader. Default: false\n\n### Message Size\n- `max.message.bytes` - Maximum size of a message. Default: 1048588 (~1MB)\n- `message.timestamp.type` - Whether to use CreateTime or LogAppendTime. Default: \"CreateTime\"\n\nFor a complete list of configurations, refer to the [Kafka documentation](https://kafka.apache.org/documentation/#topicconfigs).\n\n\u003e **Note:** Increasing the partition count is supported without recreating the topic. However, decreasing partitions requires topic recreation.\n\n## Import\n\nExisting Kafka topics can be imported using the topic name:\n\n```sh\n$ pulumi import kafka:index/topic:Topic example example-topic\n```\n\n",
            "properties": {
                "config": {
                    "type": "object",
                    "additionalProperties": {
                        "type": "string"
                    },
                    "description": "A map of string k/v attributes.\n"
                },
                "name": {
                    "type": "string",
                    "description": "The name of the topic.\n"
                },
                "partitions": {
                    "type": "integer",
                    "description": "Number of partitions.\n"
                },
                "replicationFactor": {
                    "type": "integer",
                    "description": "Number of replicas.\n"
                }
            },
            "required": [
                "name",
                "partitions",
                "replicationFactor"
            ],
            "inputProperties": {
                "config": {
                    "type": "object",
                    "additionalProperties": {
                        "type": "string"
                    },
                    "description": "A map of string k/v attributes.\n"
                },
                "name": {
                    "type": "string",
                    "description": "The name of the topic.\n",
                    "willReplaceOnChanges": true
                },
                "partitions": {
                    "type": "integer",
                    "description": "Number of partitions.\n"
                },
                "replicationFactor": {
                    "type": "integer",
                    "description": "Number of replicas.\n"
                }
            },
            "requiredInputs": [
                "partitions",
                "replicationFactor"
            ],
            "stateInputs": {
                "description": "Input properties used for looking up and filtering Topic resources.\n",
                "properties": {
                    "config": {
                        "type": "object",
                        "additionalProperties": {
                            "type": "string"
                        },
                        "description": "A map of string k/v attributes.\n"
                    },
                    "name": {
                        "type": "string",
                        "description": "The name of the topic.\n",
                        "willReplaceOnChanges": true
                    },
                    "partitions": {
                        "type": "integer",
                        "description": "Number of partitions.\n"
                    },
                    "replicationFactor": {
                        "type": "integer",
                        "description": "Number of replicas.\n"
                    }
                },
                "type": "object"
            }
        },
        "kafka:index/userScramCredential:UserScramCredential": {
            "description": "\n\n## Import\n\nSCRAM credentials can be imported using the format `username|scram_mechanism|password`:\n\n```sh\n$ pulumi import kafka:index/userScramCredential:UserScramCredential example 'my-user|SCRAM-SHA-256|my-password'\n```\n\n",
            "properties": {
                "password": {
                    "type": "string",
                    "description": "The password of the credential (deprecated, use password_wo instead)\n",
                    "secret": true
                },
                "passwordWoVersion": {
                    "type": "string",
                    "description": "Version identifier for the write-only password to track changes\n"
                },
                "scramIterations": {
                    "type": "integer",
                    "description": "The number of SCRAM iterations used when generating the credential\n"
                },
                "scramMechanism": {
                    "type": "string",
                    "description": "The SCRAM mechanism used to generate the credential (SCRAM-SHA-256, SCRAM-SHA-512)\n"
                },
                "username": {
                    "type": "string",
                    "description": "The name of the credential\n"
                }
            },
            "required": [
                "scramMechanism",
                "username"
            ],
            "inputProperties": {
                "password": {
                    "type": "string",
                    "description": "The password of the credential (deprecated, use password_wo instead)\n",
                    "secret": true
                },
                "passwordWoVersion": {
                    "type": "string",
                    "description": "Version identifier for the write-only password to track changes\n"
                },
                "scramIterations": {
                    "type": "integer",
                    "description": "The number of SCRAM iterations used when generating the credential\n"
                },
                "scramMechanism": {
                    "type": "string",
                    "description": "The SCRAM mechanism used to generate the credential (SCRAM-SHA-256, SCRAM-SHA-512)\n",
                    "willReplaceOnChanges": true
                },
                "username": {
                    "type": "string",
                    "description": "The name of the credential\n",
                    "willReplaceOnChanges": true
                }
            },
            "requiredInputs": [
                "scramMechanism",
                "username"
            ],
            "stateInputs": {
                "description": "Input properties used for looking up and filtering UserScramCredential resources.\n",
                "properties": {
                    "password": {
                        "type": "string",
                        "description": "The password of the credential (deprecated, use password_wo instead)\n",
                        "secret": true
                    },
                    "passwordWoVersion": {
                        "type": "string",
                        "description": "Version identifier for the write-only password to track changes\n"
                    },
                    "scramIterations": {
                        "type": "integer",
                        "description": "The number of SCRAM iterations used when generating the credential\n"
                    },
                    "scramMechanism": {
                        "type": "string",
                        "description": "The SCRAM mechanism used to generate the credential (SCRAM-SHA-256, SCRAM-SHA-512)\n",
                        "willReplaceOnChanges": true
                    },
                    "username": {
                        "type": "string",
                        "description": "The name of the credential\n",
                        "willReplaceOnChanges": true
                    }
                },
                "type": "object"
            }
        }
    },
    "functions": {
        "kafka:index:getTopic": {
            "inputs": {
                "description": "A collection of arguments for invoking getTopic.\n",
                "properties": {
                    "name": {
                        "type": "string"
                    }
                },
                "type": "object",
                "required": [
                    "name"
                ]
            },
            "outputs": {
                "description": "A collection of values returned by getTopic.\n",
                "properties": {
                    "config": {
                        "additionalProperties": {
                            "type": "string"
                        },
                        "type": "object"
                    },
                    "id": {
                        "description": "The provider-assigned unique ID for this managed resource.\n",
                        "type": "string"
                    },
                    "name": {
                        "type": "string"
                    },
                    "partitions": {
                        "type": "integer"
                    },
                    "replicationFactor": {
                        "type": "integer"
                    }
                },
                "required": [
                    "config",
                    "name",
                    "partitions",
                    "replicationFactor",
                    "id"
                ],
                "type": "object"
            }
        },
        "kafka:index:getTopics": {
            "outputs": {
                "description": "A collection of values returned by getTopics.\n",
                "properties": {
                    "id": {
                        "description": "The provider-assigned unique ID for this managed resource.\n",
                        "type": "string"
                    },
                    "lists": {
                        "description": "A list containing all the topics.\n",
                        "items": {
                            "$ref": "#/types/kafka:index/getTopicsList:getTopicsList"
                        },
                        "type": "array"
                    }
                },
                "required": [
                    "lists",
                    "id"
                ],
                "type": "object"
            }
        },
        "pulumi:providers:kafka/terraformConfig": {
            "description": "This function returns a Terraform config object with terraform-namecased keys,to be used with the Terraform Module Provider.",
            "inputs": {
                "properties": {
                    "__self__": {
                        "type": "ref",
                        "$ref": "#/provider"
                    }
                },
                "type": "pulumi:providers:kafka/terraformConfig",
                "required": [
                    "__self__"
                ]
            },
            "outputs": {
                "properties": {
                    "result": {
                        "additionalProperties": {
                            "$ref": "pulumi.json#/Any"
                        },
                        "type": "object"
                    }
                },
                "required": [
                    "result"
                ],
                "type": "object"
            }
        }
    }
}